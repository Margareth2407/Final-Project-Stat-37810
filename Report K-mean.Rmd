---
title: "Report K mean"
author: "Margarita Orlova, Kenneth Ruiter, Patrick Walker"
date: "November 3, 2018"
output: html_document
---
##K-mean classifier

In the code below we cluster data from wine dataset, using k-mean method.
Our function return list with 2 objects: means of clusters and results of our clustering. We receive clusters with 47, 62, 69 observations.
Note that k-mean function built in R produce the same result, meaning that our code is correct.

```{r}
library(rattle) #import data
library(fpc) #import plot
data(wine)

mywine <- as.matrix(wine[,-1]) # remove the existing clustering

cluster <- function(data){ #declare function
  nrows <- length(data[,1]) #create variable with number of rows of data
  ncols <- length(data[1,]) #create variable with number of columns of data
  iterations <- 20
  set.seed(1) 
  means <- data[sample(1:nrows,3),] #select rows from the original data set to serve as the initial means/centers
  for(i in 1:iterations){ #for loop for each of the iterations of reassigning the means
    distances <- matrix(rep(0,3*nrows),nrow = nrows) #distances matrix initialized
    mindistances <- matrix(rep(0, 2*nrows), nrow = nrows) #mindistances matrix initialized
    for(j in 1:nrows){ #for each row
      for(k in 1:3){ #for each cluster
        distances[j,k] <- sum((data[j,]-means[k,])^2) 
        #finds the difference between the row j and the mean ascribed to cluster K
      }
      mindistances[j,] <- c(min(distances[j,]), which.min(distances[j,])) 
      #finds the minimum distance for each row amongst the three clusters and assigns it to mindistances
      # in the first column and the second column has the cluster
    }
    for(l in 1:3){ #for each cluster
      datarows <- data[mindistances[,2]==l,] #selects the data corresponding to each of the clusters
      means[l,] <- colMeans(data[mindistances[,2]==l,])
      #the above line takes the mean of each column and stores them as the new means vector
    }
  }
  return(list(means, mindistances)) #returns means and mindistances
}
results <- cluster(mywine) 
results[[1]][,]
sum(results[[2]][,2] == 1)
sum(results[[2]][,2] == 2)
sum(results[[2]][,2] == 3)


```

```{r}
kmeans(wine[,-1],3,algorith="Lloyd")  #running R k-mean classifier for checking results of our function
```


Then we visualize our clusters to check how well are they separated. And as we see from the plot, observations are grouped adequate, however there is no distinct border between clusters.

```{r}
plotcluster(mywine, results[[2]][,2]) #plots clusters
```


Later, we have to quantify the results of k-mean clustering. In order to do that we run following code:

```{r}
require(data.table)
wine_cluster <- cbind(wine,results[[2]][,2]) #add variable with  cluster to wine dataset
colnames(wine_cluster)[15] <- "clusters" #name new variable
type_1 <-setkey(data.table((wine_cluster[wine_cluster$Type == 1,2:14]))) #subgroup observation with type 1 
type_2 <-setkey(data.table((wine_cluster[wine_cluster$Type == 2,2:14]))) #subgroup observation with type 2 
type_3 <-setkey(data.table((wine_cluster[wine_cluster$Type == 3,2:14]))) #subgroup observation with type 3 
cluster_1 <-setkey(data.table((wine_cluster[wine_cluster$clusters == 1,2:14]))) #subgroup observation that are classified as claster 1 
cluster_2 <-setkey(data.table((wine_cluster[wine_cluster$clusters == 2,2:14]))) #subgroup observation that are classified as claster 2
cluster_3 <-setkey(data.table((wine_cluster[wine_cluster$clusters == 3,2:14]))) #subgroup observation that are classified as claster 3
cluster1_type1<-na.omit(cluster_1[type_1,which=TRUE]) #rows that in cluster 1 and originally typed as 1
cluster1_type2<-na.omit(cluster_1[type_2,which=TRUE]) #rows that in cluster 1 and originally typed as 2
cluster1_type3<-na.omit(cluster_1[type_3,which=TRUE]) #rows that in cluster 1 and originally typed as 3
cluster2_type1<-na.omit(cluster_2[type_1,which=TRUE]) #rows that in cluster 2 and originally typed as 1
cluster2_type2<-na.omit(cluster_2[type_2,which=TRUE]) #rows that in cluster 2 and originally typed as 2
cluster2_type3<-na.omit(cluster_2[type_3,which=TRUE]) #rows that in cluster 2 and originally typed as 3
cluster3_type1<-na.omit(cluster_3[type_1,which=TRUE]) #rows that in cluster 3 and originally typed as 1
cluster3_type2<-na.omit(cluster_3[type_2,which=TRUE]) #rows that in cluster 3 and originally typed as 2
cluster3_type3<-na.omit(cluster_3[type_3,which=TRUE]) #rows that in cluster 3 and originally typed as 3

method<-c(length(cluster1_type1),length(cluster1_type2),length(cluster1_type3),length(cluster2_type1),length(cluster2_type2),length(cluster2_type3),length(cluster3_type1),length(cluster3_type2),length(cluster3_type3)) #count rows in groups cluster-type
matrix<-matrix(method,nrow = 3,ncol = 3, byrow=TRUE) #create matrix 3 by 3 
colnames(matrix) <- c("Type 1","Type 2","Type 3") #set column names
rownames(matrix) <- c("Cluster 1","Cluster 2","Cluster 3") #set row names
matrix
```

The output of following code is matrix of 3 by 3 that can be interpreted as follows: intersection of row Cluster 1 and column Type 1 is amount of observation in cluster 1 which are also type 1 in original wine file. Sum by rows must be equal to size of clusters (47,62,69) and it is exactly what we observe.

As we see, cluster 1  consist of type 1 wine, with only one type 2 wine. Cluster 2 can be interpreted as mostly type 2 wines, with 19 misgrouped type 3 wines. Cluster 3 is not that easy to interpret as it includes all types of wine. However, we can say that it is type 3 wine cluster.



##K-means for scaled data

Using the same code, we use scaled data this time. We will not define function again and use code above.
Function returns clusters with 51, 61 and 66 observations. As we see from the plot, scaling the data improves clustering a lot. After scaling observation can be distinctly grouped with clear borders between clusters. 

```{r}
data(wine) #scale data
set.seed(0)
mywine_scaled <- as.matrix(scale(wine[,-1])) # remove the existing clustering

results <- cluster(mywine_scaled)

results[[1]][,]
sum(results[[2]][,2] == 1)
sum(results[[2]][,2] == 2)
sum(results[[2]][,2] == 3)

plotcluster(mywine, results[[2]][,2]) #plots clusters
```

Our method for checking quality of clustering also shows improvement over unscaled data.  For example, cluster 2 fully consist of type 2 wine. Cluster 1 became assosiated with type 3 wine with only 3 observations of type 2. Cluster 2 attributes type 1 wine with only 2 wrongly clustered obseration. 
Thus, after scaling data k-mean cluster algorith wrongly classify only 5 rows which is 3% of total dataset.
 
```{r}
wine_cluster_scaled <- cbind(wine,results[[2]][,2])
colnames(wine_cluster_scaled)[15] <- "clusters"
type_1 <-setkey(data.table((wine_cluster_scaled[wine_cluster_scaled$Type == 1,2:14])))
type_2 <-setkey(data.table((wine_cluster_scaled[wine_cluster_scaled$Type == 2,2:14])))
type_3 <-setkey(data.table((wine_cluster_scaled[wine_cluster_scaled$Type == 3,2:14])))
cluster_1 <-setkey(data.table((wine_cluster_scaled[wine_cluster_scaled$clusters == 1,2:14])))
cluster_2 <-setkey(data.table((wine_cluster_scaled[wine_cluster_scaled$clusters == 2,2:14])))
cluster_3 <-setkey(data.table((wine_cluster_scaled[wine_cluster_scaled$clusters == 3,2:14])))
cluster1_type1<-na.omit(cluster_1[type_1,which=TRUE])
cluster1_type2<-na.omit(cluster_1[type_2,which=TRUE])
cluster1_type3<-na.omit(cluster_1[type_3,which=TRUE])
cluster2_type1<-na.omit(cluster_2[type_1,which=TRUE])
cluster2_type2<-na.omit(cluster_2[type_2,which=TRUE])
cluster2_type3<-na.omit(cluster_2[type_3,which=TRUE])
cluster3_type1<-na.omit(cluster_3[type_1,which=TRUE])
cluster3_type2<-na.omit(cluster_3[type_2,which=TRUE])
cluster3_type3<-na.omit(cluster_3[type_3,which=TRUE])

method<-c(length(cluster1_type1),length(cluster1_type2),length(cluster1_type3),length(cluster2_type1),length(cluster2_type2),length(cluster2_type3),length(cluster3_type1),length(cluster3_type2),length(cluster3_type3))
matrix<-matrix(method,nrow = 3,ncol = 3, byrow=TRUE)
colnames(matrix) <- c("Type 1","Type 2","Type 3")
rownames(matrix) <- c("Cluster 1","Cluster 2","Cluster 3")
matrix

```





##K-mean for iris dataset
In the following section we will run previously defined function on iris dataset and only new code will be comented, since we are running the same procedure.

Function cluster dataset into groups of 39, 50 and 61 observations. From the plot we can observe, that cluster 1 is separated from other data, but clusters 2 and 3 are hard to distinguish. 

```{r}
data(iris)
iris <- as.matrix(iris[,1:4]) # remove column with species
set.seed(421)

results <- cluster(iris) 

results[[1]][,]
sum(results[[2]][,2] == 1)
sum(results[[2]][,2] == 2)
sum(results[[2]][,2] == 3)
plotcluster(iris, results[[2]][,2]) 

```

We can also notice that from this dataset k-mean method do cluster species 1 properly, but do more mistakes in grouping species 2 and 3 because 19 out of 150 observations were misgrouped (12,6% from total dataset).


```{r}
data(iris)
iris <- as.matrix(iris) 
iris[iris=="setosa"] <- 1 #recode variable species 
iris[iris=="versicolor"] <- 2 #recode variable species
iris[iris=="virginica"] <- 3 #recode variable species
iris_clusters <- cbind(results[[2]][,2],iris) #add first column with cluster
colnames(iris_clusters)[1] <- "clusters"

iris_clusters<-as.data.frame(iris_clusters)

require(data.table)
species_1 <-setkey(data.table((iris_clusters[iris_clusters$Species == 1,2:5])))
species_2 <-setkey(data.table((iris_clusters[iris_clusters$Species == 2,2:5])))
species_3 <-setkey(data.table((iris_clusters[iris_clusters$Species == 3,2:5])))
cluster_1 <-setkey(data.table((iris_clusters[iris_clusters$clusters == 1,2:5])))
cluster_2 <-setkey(data.table((iris_clusters[iris_clusters$clusters == 2,2:5])))
cluster_3 <-setkey(data.table((iris_clusters[iris_clusters$clusters == 3,2:5])))
cluster1_species_1<-na.omit(cluster_1[species_1,which=TRUE])
cluster1_species_2<-na.omit(cluster_1[species_2,which=TRUE])
cluster1_species_3<-na.omit(cluster_1[species_3,which=TRUE])
cluster2_species_1<-na.omit(cluster_2[species_1,which=TRUE])
cluster2_species_2<-na.omit(cluster_2[species_2,which=TRUE])
cluster2_species_3<-na.omit(cluster_2[species_3,which=TRUE])
cluster3_species_1<-na.omit(cluster_3[species_1,which=TRUE])
cluster3_species_2<-na.omit(cluster_3[species_2,which=TRUE])
cluster3_species_3<-na.omit(cluster_3[species_3,which=TRUE])

method<-c(length(cluster1_species_1),length(cluster1_species_2),length(cluster1_species_3),length(cluster2_species_1),length(cluster2_species_2),length(cluster2_species_3),length(cluster3_species_1),length(cluster3_species_2),length(cluster3_species_3))
matrix<-matrix(method,nrow = 3,ncol = 3, byrow=TRUE)
colnames(matrix) <- c("Species 1","Species 2","Species 3")
rownames(matrix) <- c("Cluster 1","Cluster 2","Cluster 3")
matrix

```


##K-means for iris scaled data

In the code below we first scale iris data in order to improve results of k-mean clustering.
We receive groups of 50, 56, 44 observations. From the plot we can observe, that again cluster 1 is separated from majority of the data and thus clustered properly, but clusters 2 and 3 still had to distinguish. 

```{r}
data(iris)
iris <- as.matrix(iris[,1:4]) # remove column with species
iris_scaled <- as.matrix(scale(iris)) #scale data
set.seed(421)

results <- cluster(iris_scaled) 

results[[1]][,]
sum(results[[2]][,2] == 1)
sum(results[[2]][,2] == 2)
sum(results[[2]][,2] == 3)
plotcluster(iris, results[[2]][,2]) 
```


Corresponding with result of unscaled data, cluster 1 assosiated with species 1 is matched correctly, however scaling do not improve clustering for species 2 and 3. In fact, instead of 19 misgrouped observation we receive 30 (16% from dataset). Thus, we can conclude that scaling data does not always improve results of clustering and in some cases can negatively affect it.

```{r}
data(iris)
iris <- as.matrix(iris)
iris_scaled <- cbind(iris_scaled,iris[,5]) #add species column 
iris_scaled[iris_scaled=="setosa"] <- 1 #recode variable species 
iris_scaled[iris_scaled=="versicolor"] <- 2 #recode variable species
iris_scaled[iris_scaled=="virginica"] <- 3 #recode variable species

iris_scaled <- cbind(results[[2]][,2],iris_scaled) #add first column with cluster
colnames(iris_scaled)[1] <- "clusters"
colnames(iris_scaled)[6] <- "Species"

iris_scaled<-as.data.frame(iris_scaled)

require(data.table)
species_1 <-setkey(data.table((iris_scaled[iris_scaled$Species == 1,2:5])))
species_2 <-setkey(data.table((iris_scaled[iris_scaled$Species == 2,2:5])))
species_3 <-setkey(data.table((iris_scaled[iris_scaled$Species == 3,2:5])))
cluster_1 <-setkey(data.table((iris_scaled[iris_scaled$clusters == 1,2:5])))
cluster_2 <-setkey(data.table((iris_scaled[iris_scaled$clusters == 2,2:5])))
cluster_3 <-setkey(data.table((iris_scaled[iris_scaled$clusters == 3,2:5])))


cluster1_species_1<-na.omit(cluster_1[species_1,which=TRUE])
cluster1_species_2<-na.omit(cluster_1[species_2,which=TRUE])
cluster1_species_3<-na.omit(cluster_1[species_3,which=TRUE])
cluster2_species_1<-na.omit(cluster_2[species_1,which=TRUE])
cluster2_species_2<-na.omit(cluster_2[species_2,which=TRUE])
cluster2_species_3<-na.omit(cluster_2[species_3,which=TRUE])
cluster3_species_1<-na.omit(cluster_3[species_1,which=TRUE])
cluster3_species_2<-na.omit(cluster_3[species_2,which=TRUE])
cluster3_species_3<-na.omit(cluster_3[species_3,which=TRUE])

method<-c(length(cluster1_species_1),length(cluster1_species_2),length(cluster1_species_3),length(cluster2_species_1),length(cluster2_species_2),length(cluster2_species_3),length(cluster3_species_1),length(cluster3_species_2),length(cluster3_species_3))
matrix<-matrix(method,nrow = 3,ncol = 3, byrow=TRUE)
colnames(matrix) <- c("Species 1","Species 2","Species 3")
rownames(matrix) <- c("Cluster 1","Cluster 2","Cluster 3")
matrix

```
